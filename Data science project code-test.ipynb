{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3efd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de84a45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\yaswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"popular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623e351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ceaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('Group3-news-text-sanitized (1).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee27530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10138"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates('Tweet',keep='first')\n",
    "df['Tweet'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a3a95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Hey! How are you?</td>\n",
       "      <td>hey how are you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>whats up man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>i love fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>summer is lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>my car is so fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10318</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>Make man pikin crash ??????</td>\n",
       "      <td>make man pikin crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10319</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>Disregard my snap story there is an angry whit...</td>\n",
       "      <td>disregard my snap story there is an angry whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10320</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>#tornado #singapore Mac and #cheese #around th...</td>\n",
       "      <td>tornado singapore mac and cheese around the wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10321</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>0.3367</td>\n",
       "      <td>Check out more data on Upper Wabash reservoirs...</td>\n",
       "      <td>check out more data on upper wabash reservoirs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10322</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.3342</td>\n",
       "      <td>Drowning' - Acrylic 08.05.15 https://t.co/X17f...</td>\n",
       "      <td>drowning  acrylic 080515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10138 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category  Confidence  \\\n",
       "0      Not Relevant      1.0000   \n",
       "1      Not Relevant      1.0000   \n",
       "2      Not Relevant      1.0000   \n",
       "3      Not Relevant      1.0000   \n",
       "4      Not Relevant      1.0000   \n",
       "...             ...         ...   \n",
       "10318      Relevant      0.3994   \n",
       "10319      Relevant      0.3994   \n",
       "10320      Relevant      0.3982   \n",
       "10321  Not Relevant      0.3367   \n",
       "10322      Relevant      0.3342   \n",
       "\n",
       "                                                   Tweet  \\\n",
       "0                                      Hey! How are you?   \n",
       "1                                         What's up man?   \n",
       "2                                          I love fruits   \n",
       "3                                       Summer is lovely   \n",
       "4                                      My car is so fast   \n",
       "...                                                  ...   \n",
       "10318                        Make man pikin crash ??????   \n",
       "10319  Disregard my snap story there is an angry whit...   \n",
       "10320  #tornado #singapore Mac and #cheese #around th...   \n",
       "10321  Check out more data on Upper Wabash reservoirs...   \n",
       "10322  Drowning' - Acrylic 08.05.15 https://t.co/X17f...   \n",
       "\n",
       "                                           Cleaned_Tweet  \n",
       "0                                        hey how are you  \n",
       "1                                           whats up man  \n",
       "2                                          i love fruits  \n",
       "3                                       summer is lovely  \n",
       "4                                      my car is so fast  \n",
       "...                                                  ...  \n",
       "10318                              make man pikin crash   \n",
       "10319  disregard my snap story there is an angry whit...  \n",
       "10320  tornado singapore mac and cheese around the wo...  \n",
       "10321  check out more data on upper wabash reservoirs...  \n",
       "10322                          drowning  acrylic 080515   \n",
       "\n",
       "[10138 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Cleaned_Tweet\"] = [re.sub(r\"(@[A-Za-z0–9_]+)|[^\\w\\s]|#|http\\S+\", \"\", v.lower()) for v in df[\"Tweet\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a9e8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>hey how are you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>whats up man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>i love fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>summer is lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>my car is so fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10318</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>make man pikin crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10319</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>disregard my snap story there is an angry whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10320</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>tornado singapore mac and cheese around the wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10321</th>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>0.3367</td>\n",
       "      <td>check out more data on upper wabash reservoirs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10322</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.3342</td>\n",
       "      <td>drowning  acrylic 080515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10138 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category  Confidence  \\\n",
       "0      Not Relevant      1.0000   \n",
       "1      Not Relevant      1.0000   \n",
       "2      Not Relevant      1.0000   \n",
       "3      Not Relevant      1.0000   \n",
       "4      Not Relevant      1.0000   \n",
       "...             ...         ...   \n",
       "10318      Relevant      0.3994   \n",
       "10319      Relevant      0.3994   \n",
       "10320      Relevant      0.3982   \n",
       "10321  Not Relevant      0.3367   \n",
       "10322      Relevant      0.3342   \n",
       "\n",
       "                                           Cleaned_Tweet  \n",
       "0                                        hey how are you  \n",
       "1                                           whats up man  \n",
       "2                                          i love fruits  \n",
       "3                                       summer is lovely  \n",
       "4                                      my car is so fast  \n",
       "...                                                  ...  \n",
       "10318                              make man pikin crash   \n",
       "10319  disregard my snap story there is an angry whit...  \n",
       "10320  tornado singapore mac and cheese around the wo...  \n",
       "10321  check out more data on upper wabash reservoirs...  \n",
       "10322                          drowning  acrylic 080515   \n",
       "\n",
       "[10138 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Tweet',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35dcdf5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (86809788.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [12]\u001b[1;36m\u001b[0m\n\u001b[1;33m    df['cat']=df['Category'].replace('Not Relevant': 0 ,'Relevant':1)\u001b[0m\n\u001b[1;37m                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df['cat']=df['Category'].replace('Not Relevant': 0 ,'Relevant':1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a4f4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_to_replace = {'Relevant':1, 'Not Relevant':0}\n",
    "df['Category'] = df['Category'].map(vals_to_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13d7b04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., nan])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d934bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0607d05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d19bfefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0be5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['Cleaned_Tweet'],df['Category'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11d8ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14bf421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = vectorizer.fit_transform(train_texts)\n",
    "test_features = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d7be0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5dffb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "134bb1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8107467404188068\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceae87b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier1 = MultinomialNB()\n",
    "classifier1.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b27cc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier1.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7773b7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf928462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8060055314105097\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14991899",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7307739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9861fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
